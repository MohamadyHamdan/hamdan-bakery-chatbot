{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03jahEPWaXNo",
        "outputId": "3cde1a22-d1e9-43e9-97ef-59067fe96b46",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.2)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.2)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.19.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.37.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.5\n"
          ]
        }
      ],
      "source": [
        "!pip install openai gradio python-dotenv PyMuPDF\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# If you have a .env file with: OPENAI_API_KEY=your_key_here\n",
        "load_dotenv()\n",
        "\n",
        "# OR directly set the key (temporary for testing)\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxxxxxxxxxxxxxx\"\n",
        "\n",
        "# Check if the key is loaded correctly\n",
        "if \"OPENAI_API_KEY\" in os.environ:\n",
        "    print(\" OpenAI API key loaded.\")\n",
        "else:\n",
        "    print(\" API key not found. Please set it.\")\n"
      ],
      "metadata": {
        "id": "nyNnizC1aiHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dee3ad7-5c12-4675-8cf4-92fa8c0bc388"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ OpenAI API key loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "\n",
        "# Correct paths based on your Colab file tree\n",
        "txt_path = \"/business_summary.txt\"\n",
        "pdf_path = \"/about_business.pdf\"\n",
        "\n",
        "def load_txt(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def load_pdf(path):\n",
        "    text = \"\"\n",
        "    with fitz.open(path) as doc:\n",
        "        for page in doc:\n",
        "            text += page.get_text()\n",
        "    return text\n",
        "\n",
        "try:\n",
        "    business_text = load_txt(txt_path)\n",
        "    business_pdf_text = load_pdf(pdf_path)\n",
        "    knowledge_base = business_text + \"\\n\\n\" + business_pdf_text\n",
        "    print(\" Knowledge base loaded successfully.\")\n",
        "    print(f\"Characters loaded: {len(knowledge_base)}\")\n",
        "except Exception as e:\n",
        "    print(\" Error loading files:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbygTkb_6ays",
        "outputId": "d94354c9-0b63-4c96-8665-07513b1147ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Knowledge base loaded successfully.\n",
            "Characters loaded: 4400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2 - Tool functions\n",
        "\n",
        "def record_customer_interest(email: str, name: str, message: str):\n",
        "    \"\"\"\n",
        "    Logs a potential customer lead. In this assignment, printing is enough.\n",
        "    \"\"\"\n",
        "    log = f\"[LEAD] Name: {name}, Email: {email}, Message: {message}\"\n",
        "    print(log)\n",
        "    # Optional: save to a file\n",
        "    with open(\"customer_leads.log\", \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(log + \"\\n\")\n",
        "\n",
        "def record_feedback(question: str):\n",
        "    \"\"\"\n",
        "    Logs questions the chatbot couldn't answer.\n",
        "    \"\"\"\n",
        "    log = f\"[FEEDBACK] Unanswered question: {question}\"\n",
        "    print(log)\n",
        "    # Optional: save to a file\n",
        "    with open(\"feedback.log\", \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(log + \"\\n\")\n",
        "\n",
        "# Test the functions\n",
        "record_customer_interest(\"test@example.com\", \"John Doe\", \"Interested in sourdough delivery.\")\n",
        "record_feedback(\"Do you offer gluten-free croissants?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODcdyKLu7j47",
        "outputId": "cc467678-51c1-4488-a4d2-226ab1edb61d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LEAD] Name: John Doe, Email: test@example.com, Message: Interested in sourdough delivery.\n",
            "[FEEDBACK] Unanswered question: Do you offer gluten-free croissants?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3 - System Prompt & Chat Setup\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "system_prompt = f\"\"\"\n",
        "You are hamdan_bakery, a friendly neighborhood artisan bakery chatbot üçû.\n",
        "Use ONLY the information provided below to answer user questions.\n",
        "Do not make up or invent details ‚Äî if you don't find the answer,\n",
        "call the record_feedback tool.\n",
        "\n",
        "Knowledge base:\n",
        "{knowledge_base}\n",
        "\n",
        "Guidelines:\n",
        "- Speak in a warm and concise tone, as if you are the bakery.\n",
        "- When users ask about orders, products, or services, refer to the text above.\n",
        "- Encourage users to leave their name and email for pre-orders, custom cakes, or delivery.\n",
        "- If a question is outside your knowledge, log it with record_feedback(question).\n",
        "\"\"\"\n",
        "\n",
        "print(\"System prompt set.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8YKvT997sVd",
        "outputId": "b7ea18af-5c70-419b-919b-7d06bf6cd35a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ System prompt set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4 - Agent interaction loop using OpenAI API\n",
        "\n",
        "import json\n",
        "\n",
        "# Define the tool schemas for the model\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"record_customer_interest\",\n",
        "            \"description\": \"Record customer leads with name, email, and message\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"email\": {\"type\": \"string\"},\n",
        "                    \"name\": {\"type\": \"string\"},\n",
        "                    \"message\": {\"type\": \"string\"}\n",
        "                },\n",
        "                \"required\": [\"email\", \"name\", \"message\"]\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"record_feedback\",\n",
        "            \"description\": \"Log a question the bot cannot answer\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"question\": {\"type\": \"string\"}\n",
        "                },\n",
        "                \"required\": [\"question\"]\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "def run_agent(user_input, chat_history):\n",
        "    \"\"\"\n",
        "    Handles user input, sends it to OpenAI, executes tools if needed, and returns the assistant's response.\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt}\n",
        "    ] + chat_history + [{\"role\": \"user\", \"content\": user_input}]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",\n",
        "    )\n",
        "\n",
        "    message = response.choices[0].message\n",
        "\n",
        "    # Check if the model requested a tool call\n",
        "    if message.tool_calls:\n",
        "        for tool_call in message.tool_calls:\n",
        "            tool_name = tool_call.function.name\n",
        "            tool_args = json.loads(tool_call.function.arguments)\n",
        "\n",
        "            if tool_name == \"record_customer_interest\":\n",
        "                record_customer_interest(**tool_args)\n",
        "                return \"Thanks for your interest! We‚Äôve logged your info and will get back to you soon üìù\"\n",
        "\n",
        "            elif tool_name == \"record_feedback\":\n",
        "                record_feedback(**tool_args)\n",
        "                return \"Hmm, I‚Äôm not sure about that ‚Äî but I‚Äôve logged your question so we can follow up üëå\"\n",
        "\n",
        "    # Otherwise, return the assistant's text\n",
        "    return message.content\n",
        "\n",
        "#  Quick test in notebook\n",
        "chat_history = []\n",
        "user_input = \"Hi, who is the president of Algeria?\"\n",
        "assistant_reply = run_agent(user_input, chat_history)\n",
        "chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "chat_history.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
        "\n",
        "print(\" Bot:\", assistant_reply)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIgU-48J70QL",
        "outputId": "3bb3abb0-559e-4b85-e872-51f22cbbeae8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FEEDBACK] Unanswered question: Who is the president of Algeria?\n",
            "ü§ñ Bot: Hmm, I‚Äôm not sure about that ‚Äî but I‚Äôve logged your question so we can follow up üëå\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "gr.close_all()  # closes any previously running Gradio instances\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9i6vII38VHM",
        "outputId": "4757880e-ceb8-47a0-f7de-8353f5ac545a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import traceback\n",
        "import gradio as gr\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "def chatbot_interface(user_input, history):\n",
        "    global chat_history\n",
        "    try:\n",
        "        assistant_reply = run_agent(user_input, chat_history)\n",
        "        chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "        chat_history.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
        "        return assistant_reply\n",
        "    except Exception as e:\n",
        "        print(\" Error in chatbot:\", e)\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return f\" Internal error: {e}\"\n",
        "\n",
        "demo = gr.ChatInterface(\n",
        "    fn=chatbot_interface,\n",
        "    title=\"ü•ê hamdan_bakery Chatbot\",\n",
        "    description=\"Ask me about our breads, pastries, cakes, or place an order!\",\n",
        ")\n",
        "\n",
        "demo.launch(share=True, debug=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "DyWDN5Mc8EoN",
        "outputId": "1e5017ad-dc88-47b4-ecd5-8bd3c1a58775"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://0ce1b43556da855991.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0ce1b43556da855991.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FEEDBACK] Unanswered question: Who is the CEO of hamdan_bakery?\n",
            "[FEEDBACK] Unanswered question: who is the owner of hamdan_bakery?\n",
            "[FEEDBACK] Unanswered question: who is the president of syria ?\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://0ce1b43556da855991.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}